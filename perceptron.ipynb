{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "perceptron.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMvAEZi+fLMl7mLCxIrIv/N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tissimich/Artificial-Neuron/blob/main/perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings \n",
        "from sklearn.exceptions import NotFittedError\n",
        "\n",
        "\n",
        "class Perceptron:\n",
        "    \"\"\" Implementation of Rosenblatt's Perceptron.  \"\"\"\n",
        "\n",
        "    def __init__(self): \n",
        "        # Weights of the model\n",
        "        self.__w = None\n",
        "\n",
        "        # Errors made at training process\n",
        "        self.__errors = None\n",
        "\n",
        "        # Defining learning rate\n",
        "        self.__heta = 0.01\n",
        "\n",
        "    def fit(self, X, y, epochs):\n",
        "        \"\"\"Fit, or train, the neuron on the input data\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape = (n_samples, n_features)\n",
        "            The training input samples\n",
        "        y: array-like of shape = (n_samples).\n",
        "            The target values, class labels for the training samples\n",
        "        Returns\n",
        "        -------\n",
        "        array-like of shape = (n_samples)\n",
        "            Predicted class label per sample\n",
        "        \"\"\"\n",
        "        n_samples = X.shape[0]\n",
        "        n_features = X.shape[1]\n",
        "\n",
        "        # Initialize weights vector with zeros\n",
        "        self.__w = np.zeros(n_features, )         \n",
        "\n",
        "        # Initialize error vector with zeros\n",
        "        self.__errors = np.zeros(n_samples)\n",
        "\n",
        "        # Initialize Bias\n",
        "        self.__bias = 0        \n",
        "\n",
        "        for epoch in range(epochs):\n",
        "\n",
        "            predictions = [] \n",
        "\n",
        "            for k in range(n_samples):   \n",
        "\n",
        "                y_pred = self.predict(X[k, :])\n",
        "                predictions.append(y_pred)\n",
        "\n",
        "                # Compute error\n",
        "                error = y[k] - y_pred\n",
        "                \n",
        "                # Update weights and bias\n",
        "                self.__w += self.__heta * error * X[k, :]\n",
        "                self.__bias += error\n",
        "\n",
        "        acuracy = self.accuracy(y, predictions)\n",
        "        print('Accuracy:', acuracy)\n",
        "\n",
        "        return self      \n",
        "\n",
        "    def __ActivationFunc(val):\n",
        "        \"\"\" \n",
        "        Apply the Heaviside step function.\n",
        "        Parameter\n",
        "        ---------\n",
        "        val : array-like, shape = (n_samples, )\n",
        "            \n",
        "        Returns\n",
        "        -------\n",
        "        0 if val < 0 or 1 if val >= 0\n",
        "        \"\"\"        \n",
        "        return np.heaviside(val, 1).astype(int)\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Predict class labels for samples in X.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape = (n_samples, n_features).\n",
        "            Samples for which we aim to predict the class.\n",
        "        Returns\n",
        "        -------\n",
        "        array-like of shape = (n_samples)\n",
        "            Predicted class label per sample.\n",
        "        \"\"\"\n",
        "        # Check if model is fitted\n",
        "        if self.__w is None:  \n",
        "            raise NotFittedError(\n",
        "                \"This %(name)s instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\"\n",
        "                % {\"name\": type(self).__name__}\n",
        "            )\n",
        "\n",
        "        return Perceptron.__ActivationFunc(X.dot(self.__w) + self.__bias)\n",
        "\n",
        "    def accuracy(self, y, predicted):\n",
        "        \"\"\"\n",
        "        Calculate the accuracy of predictions\n",
        "        Arguments:\n",
        "            y: array-like of shape = (n_samples)\n",
        "                Labels \n",
        "            predicted: array-like of shape = (n_samples)\n",
        "                Predicted class label per sample.\n",
        "        \"\"\"\n",
        "        return np.sum(np.array(predicted) == np.array(y)) / float(len(y))\n",
        "\n"
      ],
      "metadata": {
        "id": "Rk58tgVm9nTV"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets\n",
        "\n",
        "# testing with iris dataset\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "df = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
        "                     columns= iris['feature_names'] + ['target'])\n",
        "\n",
        "# deleting samples labeled as class 2\n",
        "df = df[df['target'] != 2]\n",
        "\n",
        "X = df.iloc[:, :4].values \n",
        "y = df.iloc[:, -1].values \n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "model = Perceptron()\n",
        "model.fit(x_train, y_train, 13)\n",
        "\n",
        "predictions = model.predict(x_test)\n",
        "\n",
        "model.accuracy(y_test, predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFZvCR4LjDR2",
        "outputId": "f60a87a8-7866-4e65-9a7a-e08382f1d1fb"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    }
  ]
}